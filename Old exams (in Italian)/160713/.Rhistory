DF[which(DF$patid == i & DF$cycno == j), ]$NEUT.m <- k[which(k$cycno == j),]$NEUT
DF[which(DF$patid == i & DF$cycno == j), ]$PLT.m <- k[which(k$cycno == j),]$PLT
}
}
for(i in DF$patid){
k <- biomarkers3[which( biomarkers3$patid == i & biomarkers3$ntest_cyc == 3),names(biomarkers3) %in% c('cycno','WBC', 'NEUT', 'PLT', 'time')]
for(j in k$cycno){
DF[which(DF$patid == i & DF$cycno == j), ]$time.a <- k[which(k$cycno == j),]$time
DF[which(DF$patid == i & DF$cycno == j), ]$WBC.a <- k[which(k$cycno == j),]$WBC
DF[which(DF$patid == i & DF$cycno == j), ]$NEUT.a <- k[which(k$cycno == j),]$NEUT
DF[which(DF$patid == i & DF$cycno == j), ]$PLT.a <- k[which(k$cycno == j),]$PLT
}
}
for(i in baseline$patid){
DF[which(DF$patid == i),]$age_in <- baseline[which(baseline$patid == i),]$age_in
}
Col = c('green','lightblue','blue','orange','red')
#COLOR VARIABLES
DF$kl <- rep(NA, N)
DF[which(DF$naus == 0),]$kl <- 'green'
DF[which(DF$naus == 1),]$kl <- 'lightblue'
DF[which(DF$naus == 2),]$kl <- 'blue'
DF[which(DF$naus == 3),]$kl <- 'orange'
DF[which(DF$naus == 4),]$kl <- 'red'
par(mfrow = c(3,2))
for( i in DF$patid){
x = DF[which(DF$patid == i), names(DF) %in% c('time.b')]
y = DF[which(DF$patid == i), names(DF) %in% c('WBC.b')]
if(DF[which(DF$patid == i),'trt'][1] == 'Reg-C'){
kl = 'blue'
}
if(DF[which(DF$patid == i),'trt'][1] == 'Reg-DI'){
kl = 'red'
}
if(baseline[which(baseline$patid == i),'age_cat'][1] == 'less than 15'){
plot(x,y, type = 'l', xlab = 'time', ylab = 'WBC', xlim = c(0,175), ylim = c(0,100), col = kl, main = '< 15years, red = Reg-DI, blue = Reg-C')
par(new = TRUE)
}
}
par(new = FALSE)
data <- read.table('radioville.txt',header=TRUE)
attach(data)
setwd("C:/Users/gianm/Desktop/TDEApplied/Labs/Extra-Geostatistics")
data <- read.table('radioville.txt',header=TRUE)
attach(data)
# create dummy: 0 = urban, 1 = vegetation
DUMMY <- rep(0,length(D))
DUMMY[which(D=='V')] <- 1
data <- data.frame(cbind(Bq,Long,Lat,DUMMY))
names(data) <- c('Bq','Long','Lat','D')
coordinates(data) <- c('Long','Lat')
head(data)
library(sp)           ## Data management
library(lattice)      ## Data management
library(geoR)         ## Geostatistics
library(gstat)        ## Geostatistics
data <- read.table('radioville.txt',header=TRUE)
attach(data)
# create dummy: 0 = urban, 1 = vegetation
DUMMY <- rep(0,length(D))
DUMMY[which(D=='V')] <- 1
data <- data.frame(cbind(Bq,Long,Lat,DUMMY))
names(data) <- c('Bq','Long','Lat','D')
coordinates(data) <- c('Long','Lat')
data <- read.table('radioville.txt',header=TRUE)
attach(data)
# create dummy: 0 = urban, 1 = vegetation
DUMMY <- rep(0,length(D))
head(data)
DUMMY[which(D=='V')] <- 1
data <- data.frame(cbind(Bq,Long,Lat,DUMMY))
names(data) <- c('Bq','Long','Lat','D')
coordinates(data) <- c('Long','Lat')
head(data)
v <- variogram(Bq ~ D, data = data)
plot(v)
v.fit1 <- fit.variogram(v, vgm(1, "Sph", 0.5))
plot(v, v.fit1, pch = 3)
v.fit1
# coefficient of the linear model:
# it sufficies to estimate the drift at two locations where we have observations,
# with D=U and D=V
# data[1,] = urbane
# data[6,] = vegetation
g.tr <- gstat(formula = Bq ~ D, data = data, model = v.fit1)
predict(g.tr, data[1,], BLUE = TRUE)
predict(g.tr, data[6,], BLUE = TRUE)
rm(list = ls())
df<- read.table('trulli.txt')
head(df)
rm(list = ls())
df<- read.table('trulli.txt')
head(df)
setwd("C:/Users/gianm/Desktop/TDEApplied/Old exams (in Italian)/160713")
rm(list = ls())
df<- read.table('trulli.txt')
head(df)
pv = c()
for(i in 1:3){
pv <- c(pv, t.test(df[,i]))
}
pv
pv <- c(pv, t.test(df[,i])$p.value)
pv = c()
for(i in 1:3){
pv <- c(pv, t.test(df[,i])$p.value)
}
pv
meas <- c(5,2,2.5)
pv = c()
for(i in 1:3){
pv <- c(pv, t.test(df[,i])$p.value, mu = meas[i])
}
pv
help(t.test)
np = c()
for(i in 1:3){
np <- c(np,shapiro.test(df[,i]))
}
np
np = c()
for(i in 1:3){
np <- c(np,shapiro.test(df[,i])$p)
}
np
meas <- c(5,2,2.5)
pv = c()
for(i in 1:3){
pv <- c(pv, t.test(df[,i], mu = meas[i])$p.value)
}
pv
rm(list = ls())
df<- read.table('trulli.txt')
head(df)
np = c()
for(i in 1:3){
np <- c(np,shapiro.test(df[,i])$p)
}
# pvalues = 0.1208939, 0.1191180, 0.3169064 sufficienti per normalità
meas <- c(5,2,2.5)
pv = c()
for(i in 1:3){
tt <- c(pv, t.test(df[,i], mu = meas[i]))
}
tt$pvalues
tt$p
tt
tt$p.value
meas <- c(5,2,2.5)
tt = c()
for(i in 1:3){
tt <- c(tt, t.test(df[,i], mu = meas[i]))
}
tt$p.value
M <- colMeans(df)
M
load('mcshapiro.test.RData')
df<- read.table('trulli.txt')
head(df)
mcshapiro.test(df)
Md <- colMeans(df)
Sd <- var(df)
IC.T2 <- cbind( Md - sqrt(cfr.fisher*diag(Sd)/n) , Md, Md + sqrt(cfr.fisher*diag(Sd)/n) )
n <- dim(df)[1]
q <- dim(df)[2]
cfr.fisher <- ((q-1)*(n-1)/(n-(q-1)))*qf(1-alpha,(q-1),n-(q-1))
Md <- colMeans(df)
Sd <- var(df)
IC.T2 <- cbind( Md - sqrt(cfr.fisher*diag(Sd)/n) , Md, Md + sqrt(cfr.fisher*diag(Sd)/n) )
# pvalues = 0.066649595, 0.658838515, 0.001465107 con confidenza del 95% posso dire che le prime due misure siano quelle
#  mentre la terza è diversa con confidenza del 99%
alpha = .05
n <- dim(df)[1]
q <- dim(df)[2]
cfr.fisher <- ((q-1)*(n-1)/(n-(q-1)))*qf(1-alpha,(q-1),n-(q-1))
Md <- colMeans(df)
Sd <- var(df)
IC.T2 <- cbind( Md - sqrt(cfr.fisher*diag(Sd)/n) , Md, Md + sqrt(cfr.fisher*diag(Sd)/n) )
IC.T2
C <- df[,1]*pi
C
df$C <- df[,1]*pi
Md <- colMeans(df)
Sd <- var(df)
alpha = .05
n <- dim(df)[1]
q <- dim(df)[2]
cfr.fisher <- ((q-1)*(n-1)/(n-(q-1)))*qf(1-alpha,(q-1),n-(q-1))
Md <- colMeans(df)
Sd <- var(df)
IC.T2 <- cbind( Md - sqrt(cfr.fisher*diag(Sd)/n) , Md, Md + sqrt(cfr.fisher*diag(Sd)/n) )
IC.T2
rm(list = ls())
df <- read.table('fishing.txt')
plot(df[,1], df[,2], pch = 16)
plot(df[,1], df[,2], pch = 16, col = df[,3])
head(df)
plot3d(df[,1],df[,2],df[,3])
open3d()
plot3d(df[,1],df[,2],df[,3])
plot3d(df[,1],df[,2],df[,3])
library(plot3D)
library(plot3d)
library(rgl)
open3d()
plot3d(df[,1],df[,2],df[,3])
df.e<- dist(df, method='euclidean') # distance matrix
df.es <- hclust(df.e, method='ward') # clustering gerarchico con ward linkage
df.es <- hclust(df.e, method='ward.D') # clustering gerarchico con ward linkage
df.e<- dist(df, method='euclidean') # distance matrix
## single linkage
df.es <- hclust(df.e, method='ward.D') # clustering gerarchico con ward linkage
x11() # dendrogramma
plot(df.es, main='euclidean-single', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(df.es, k=2) # ok fa schifo sto clustering
help(cutree)
cluster.es <- cutree(df.es, k=2)
cluster.es
dim1 <- length(cluster.es[which(cluster.es == 2)]) # cluster di dimensione 1
dim2 <- length(cluster.es[which(cluster.es == 1)]) # cluster di dimensione 159
dim1
dim2
dim2 <- length(cluster.es[which(cluster.es == 2)]) # cluster di dimensione 38
dim1
dim2
dim1 <- length(cluster.es[which(cluster.es == 1)]) # cluster di dimensione 52
dim2 <- length(cluster.es[which(cluster.es == 2)]) # cluster di dimensione 38
dim1
dim2
centroids <- apply (df, 2, function (x) tapply (x, cluster.es, mean))
centroids
plot3d(df[,1],df[,2],df[,3], col= cluster.es)
d.1 <- df[cluster.es == 1,]
d.2 <- df[cluster.es == 2,]
mcshapiro.test(d.1)
load('mcshapiro.test.RData')
mcshapiro.test(d.1)
mcshapiro.test(d.2)
p  <- 3
n1 <- dim(d.1)[1]
n2 <- dim(d.2)[1]
alpha <- 0.05
mean1 <- sapply(d.1,mean)
mean2 <- sapply(d.2,mean)
cov1  <-  cov(d.1)
cov2  <-  cov(d.2)
Sp      <- ((n1-1)*cov1 + (n2-1)*cov2)/(n1+n2-2)
delta.0 <- c(0,0)
Spinv   <- solve(Sp)
T2 <- n1*n2/(n1+n2) * (mean1-mean2-delta.0) %*% Spinv %*% (mean1-mean2-delta.0)
cfr.fisher <- (p*(n1+n2-2)/(n1+n2-1-p))*qf(1-alpha,p,n1+n2-1-p)
pvalue <- 1 - pf(T2/(p*(n1+n2-2)/(n1+n2-1-p)), p, n1+n2-1-p)
pvalue
mean1
mean2
p  <- 3
n1 <- dim(d.1)[1]
n2 <- dim(d.2)[1]
alpha <- 0.05
mean1 <- sapply(d.1,mean)
mean2 <- sapply(d.2,mean)
cov1  <-  cov(d.1)
cov2  <-  cov(d.2)
Sp      <- ((n1-1)*cov1 + (n2-1)*cov2)/(n1+n2-2)
delta.0 <- c(0,0,0)
Spinv   <- solve(Sp)
T2 <- n1*n2/(n1+n2) * (mean1-mean2-delta.0) %*% Spinv %*% (mean1-mean2-delta.0)
cfr.fisher <- (p*(n1+n2-2)/(n1+n2-1-p))*qf(1-alpha,p,n1+n2-1-p)
pvalue <- 1 - pf(T2/(p*(n1+n2-2)/(n1+n2-1-p)), p, n1+n2-1-p)
pvalue
dm <- (mean1-mean2)
A  <- rbind(c(1,0,0), c(0,1,0), c(0,0,1))
k  <- dim(A)[1]
A.s2 <- diag(A%*%Sp%*%t(A))
A.dm <- A%*%(mean1-mean2)
Bonf <- cbind(inf=A.dm - qt(1-(alpha/(2*k)), n1+n2-2) * sqrt( A.s2*(1/n1+1/n2) ),
center=A.dm,
sup=A.dm + qt(1-(alpha/(2*k)), n1+n2-2) * sqrt( A.s2*(1/n1+1/n2) ))
Bonf
Mcol <- (df[,1]+df[,2]+df[,3])/3
Mcol
M1 <- (d.1[,1]+d.1[,2]+d.1[,3])/3
M2 <- (d.2[,1]+d.2[,2]+d.2[,3])/3
p <- 1
M1 <- (d.1[,1]+d.1[,2]+d.1[,3])/3
M2 <- (d.2[,1]+d.2[,2]+d.2[,3])/3
mean1 <- mean(M1)
mean2 <- mean(M2)
cov1  <-  var(M1)
cov2  <-  var(M2)
Sp      <- ((n1-1)*cov1 + (n2-1)*cov2)/(n1+n2-2)
delta.0 <- 0
Spinv   <- solve(Sp)
T2 <- n1*n2/(n1+n2) * (mean1-mean2-delta.0) %*% Spinv %*% (mean1-mean2-delta.0)
cfr.fisher <- (p*(n1+n2-2)/(n1+n2-1-p))*qf(1-alpha,p,n1+n2-1-p)
pvalue <- 1 - pf(T2/(p*(n1+n2-2)/(n1+n2-1-p)), p, n1+n2-1-p)
pvalue
rm(list = ls())
df <- read.table('sanrocco.txt')
head(df)
levels(df$vento)
levels(df$temp)
g <- 2
b <- 2
p <- 1
n <- 5
N <- n*g*b
N
dim(df)
head(df)
# Verify the assumptions
# 1) normality (univariate) in each group
Ps <- c(shapiro.test(durata[ temp=='torrido' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='torrido' & vento=='fermo' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='fermo' ])$p)
attach(df)
# Verify the assumptions
# 1) normality (univariate) in each group
Ps <- c(shapiro.test(durata[ temp=='torrido' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='torrido' & vento=='fermo' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='fermo' ])$p)
Ps
# 2) homogeneity of variances
bartlett.test(list(durata[ temp=='torrido' & vento=='ventilato' ],
durata[ temp=='torrido' & vento=='fermo' ],
durata[ temp=='caldo' & vento=='ventilato'],
durata[ temp=='caldo' & vento=='fermo' ]))
# Fit the model:
fit <- aov(durata ~ temp + vento)
summary(fit)
names(fit)
W <- sum(fit$residuals^2)  # SS_res
var <- W/(g*b*n-g-b+1)     # SS_res/gdl(res)
var
# Estimate the great mean mu:
m <- mean(df[,1])
betaFest <- mean(df[df$vento=='fermo',1]) - m  # beta.2
tauAC  <- mean(df[df$temp=='torrido',1]) - m  # tau.1
tauCA  <- mean(df[df$temp=='caldo',1]) - m  # tau.2
betaFest <- mean(df[df$vento=='ventilato',1]) - m  # beta.1
betaFer  <- mean(df[df$vento=='fermo',1]) - m  # beta.2
# (model without interaction!)
mAC_Fest <- m + tauAC + betaFest
mAC_Fer  <- m + tauAC + betaFer
mCA_Fest <- m + tauCA + betaFest
mCA_Fer  <- m + tauCA + betaFer
head(df)
rm(list = ls())
df <- read.table('sanrocco.txt')
head(df)
g <- 2
b <- 2
p <- 1
n <- 5
N <- dim(df)[1]
detach(df)
attach(df)
# Verify the assumptions
# 1) normality (univariate) in each group
Ps <- c(shapiro.test(durata[ temp=='torrido' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='torrido' & vento=='fermo' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='fermo' ])$p)
# pvalues = 0.3030448, 0.6067242, 0.6721671, 0.1251575
# 2) homogeneity of variances
bartlett.test(list(durata[ temp=='torrido' & vento=='ventilato' ],
durata[ temp=='torrido' & vento=='fermo' ],
durata[ temp=='caldo' & vento=='ventilato'],
durata[ temp=='caldo' & vento=='fermo' ]))
# pvalue = 0.251
# ok le ipotesi
# Fit the model:
fit <- aov(durata ~ temp + vento)
summary(fit)
# vento è molto significativa ma temp no
names(fit)
# Estimate variances
W <- sum(fit$residuals^2)  # SS_res
var <- W/(g*b*n-g-b+1)     # SS_res/gdl(res)
# var = 0.05381381
# Estimate the great mean mu:
m <- mean(df[,1])
# Estimate tau.i, beta.j:
tauAC  <- mean(df[df$temp=='torrido',1]) - m  # tau.1
tauCA  <- mean(df[df$temp=='caldo',1]) - m  # tau.2
betaFest <- mean(df[df$vento=='ventilato',1]) - m  # beta.1
betaFer  <- mean(df[df$vento=='fermo',1]) - m  # beta.2
# Point-wise estimates of mean duration of travels
# (model without interaction!)
mAC_Fest <- m + tauAC + betaFest
mAC_Fer  <- m + tauAC + betaFer
mCA_Fest <- m + tauCA + betaFest
mCA_Fer  <- m + tauCA + betaFer
durata[ temp=='torrido' & vento=='ventilato' ]
mean(durata[ temp=='torrido' & vento=='ventilato' ])
mean(durata[ temp=='caldo' & vento=='ventilato' ])
mean(durata[ temp=='caldo' & vento=='fermo' ])
mean(durata[ temp=='torrido' & vento=='fermo' ])
g <- 2
b <- 2
p <- 1
N <- dim(df)[1]
detach(df)
attach(df)
rm(list = ls())
df <- read.table('sanrocco.txt')
head(df)
g <- 2
b <- 2
p <- 1
N <- dim(df)[1]
detach(df)
attach(df)
# Verify the assumptions
# 1) normality (univariate) in each group
Ps <- c(shapiro.test(durata[ temp=='torrido' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='torrido' & vento=='fermo' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='ventilato' ])$p,
shapiro.test(durata[ temp=='caldo' & vento=='fermo' ])$p)
# pvalues = 0.3030448, 0.6067242, 0.6721671, 0.1251575
# 2) homogeneity of variances
bartlett.test(list(durata[ temp=='torrido' & vento=='ventilato' ],
durata[ temp=='torrido' & vento=='fermo' ],
durata[ temp=='caldo' & vento=='ventilato'],
durata[ temp=='caldo' & vento=='fermo' ]))
# pvalue = 0.251
# ok le ipotesi
# Fit the model:
fit <- aov(durata ~ temp + vento)
summary(fit)
# vento è molto significativa ma temp no
names(fit)
# Estimate variances
W <- sum(fit$residuals^2)  # SS_res
var <- W/(g*b*n-g-b+1)     # SS_res/gdl(res)
# var = 0.05381381
# Estimate the great mean mu:
m <- mean(df[,1])
# Estimate tau.i, beta.j:
tauAC  <- mean(df[df$temp=='torrido',1]) - m  # tau.1
tauCA  <- mean(df[df$temp=='caldo',1]) - m  # tau.2
betaFest <- mean(df[df$vento=='ventilato',1]) - m  # beta.1
betaFer  <- mean(df[df$vento=='fermo',1]) - m  # beta.2
# Point-wise estimates of mean duration of travels
# (model without interaction!)
mAC_Fest <- m + tauAC + betaFest
mAC_Fer  <- m + tauAC + betaFer
mCA_Fest <- m + tauCA + betaFest
mCA_Fer  <- m + tauCA + betaFer
var <- W/(N-g-b+1)     # SS_res/gdl(res)
summary(fit)
# Fit the model:
fit <- aov(durata ~ vento)
summary(fit)
# vento è molto significativa ma temp no
names(fit)
# Estimate variances
W <- sum(fit$residuals^2)  # SS_res
var <- W/(N-g-b+1)     # SS_res/gdl(res)
betaFest <- mean(df[df$vento=='ventilato',1]) # beta.1
betaFer  <- mean(df[df$vento=='fermo',1]) # beta.2
betaFer
var <- W/(N-g-b+1)     # SS_res/gdl(res)
betaFest <- mean(df[df$vento=='ventilato',1]) # beta.1
betaFer  <- mean(df[df$vento=='fermo',1]) # beta.2
rm(list = ls())
rm(list = ls())
pu <- read.table('puglia.txt')
lo <- read.table('lombardia.txt')
head(lo)
dim(lo)
head(pu)
pu$region <- 'puglia'
lo$region <- 'lombardia'
df <- rbind(pu,lo)
dim(df)
tail(df)
mod1 <- lm(spesa~orecchiette + cime + orecchiette:region + cime:region)
mod1 <- lm(spesa~orecchiette + cime + orecchiette:region + cime:region, data = df)
summary(mod1)
vif(mod1)
library(car)
vif(mod1)
summary(mod1)
coef(mod1)
linearHypothesis(mod1, rbind(c(0,0,0,1,0),
c(0,0,0,0,1)), c(0,0))
linearHypothesis(mod1, c(0,0,0,0,1), 0)
linearHypothesis(mod1, c(0,0,0,1,0), 0)
mod1 <- lm(spesa~orecchiette + cime + orecchiette:region + cime:region + region, data = df)
summary(mod1) # l'unica cosa che non sembra pesare nel modello è l'interazzione tra orecchiette e regione
vif(mod1) # c'è forte collinearità nel modello
coef(mod1)
linearHypothesis(mod1, rbind(c(0,0,0,0,1,0),
c(0,0,0,0,0,1),
c(0,0,0,1,0,0)), c(0,0,0)) # pval = 2.506e-09 la regione sembra influire sul costo totale
coef(mod1)
linearHypothesis(mod1, rbind(c(0,0,0,0,1,0),
c(0,0,0,0,0,1),
c(0,0,0,1,0,0)), c(0,0,0)) # pval = 2.506e-09 la regione sembra influire sul costo totale
linearHypothesis(mod1, c(0,0,0,0,0,1), 0) # pval = 2.206e-05 la regione influenza in particolare il costo delle cime di rapa
linearHypothesis(mod1, c(0,0,0,0,1,0), 0) # pval = 0.6037 mentre non sembra influenzare il costo delle orecchiette
coef(mod1)
linearHypothesis(mod1, c(0,0,0,1,0,0), 0)
mod2 <- lm(spesa~orecchiette + cime + region, data = df)
summary(mod2)
summary(mod1) # l'unica cosa che non sembra pesare nel modello è l'interazzione tra orecchiette e regione
summary(mod2)
vif(mod2)
coef(mod2)
